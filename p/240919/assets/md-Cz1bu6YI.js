import{o as a,c as l,k as o,e as t,aa as n,q as p,s as u,B as r}from"./modules/vue-CZkfEai8.js";import{_ as m}from"./two-cols-E4OFuTVK.js";import{u as d,f}from"./slidev/context-TKC2DD0f.js";import"./index-BTercFA_.js";import"./modules/shiki-2px8ptvS.js";const c={__name:"slides.md__slidev_4",setup(E){const{$slidev:_,$nav:T,$clicksContext:s,$clicks:$,$page:g,$renderContext:A,$frontmatter:i}=d();return s.setup(),(x,e)=>(a(),l(m,p(u(r(f)(r(i),3))),{right:o(C=>e[0]||(e[0]=[])),default:o(()=>[e[1]||(e[1]=t("h2",null,"ZEETAD",-1)),e[2]||(e[2]=t("ul",null,[t("li",null,[t("p",null,'论文：Phan, Thinh, et al. "ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot End-to-End Temporal Action Detection." Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2024.')]),t("li",null,[t("p",null,[n("摘要： 现有的"),t("strong",null,"零样本 TAD"),n(" 方法对于构建【定位】和【分类】两个任务之间的联系、将 ViL 模型运用在视频理解方面存在局限。本文的 ZEETAD 框架使用双重定位模块和零样本分类模块，在 THUMOS14 数据集上展现了出色的零样本 TAD 能力，并可以将 ViL 模型的知识迁移到未见过的动作上。")])])],-1))]),_:1},16))}},B=c;export{B as default};
